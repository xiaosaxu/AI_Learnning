{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[我的知识图谱(短链接)](http://dwz.cn/7xmq8R)  \n",
    "[我的知识图谱(长链接)](http://naotu.baidu.com/file/4e0c2f82aa5280598ff75710e0226287?token=5ebf43a904d831ad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "目前来说有：1.knn 近邻算法  2.决策树算法（树的生成）3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 决策树 基本概念"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  信息量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 度量信息的单位，事件发生的概率越小，表示信息量越大，大家都知道的事件，信息量越小\n",
    "- 两个不相关的事件的信息量为两个事件信息量的和\n",
    "- 表达式为 ：![haha](https://www.zhihu.com/equation?tex=h%28x%29%3D-log_%7B2%7Dp%28x%29+)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 熵"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 熵是在结果出来之前对可能产生的信息量的期望——考虑该随机变量的所有可能取值，即所有可能发生事件所带来的信息量的期望\n",
    "- 表达式为： ![](https://www.zhihu.com/equation?tex=H%28x%29%3D-sum+%28p%28x%29log_%7B2%7Dp%28x%29+%29)\n",
    "- 也就是 ![](https://pic2.zhimg.com/80/v2-a9f081eff039a7e65f51515d4aacb34b_hd.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 条件熵"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 条件熵的定义是：定义为X给定条件下，Y的条件概率分布的熵对X的数学期望\n",
    "- 因为条件熵中X也是一个变量，意思是在一个变量X的条件下（变量X的每个值都会取），另一个变量Y熵对X的期望"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[条件熵示例](https://pic1.zhimg.com/80/v2-83f2f4b00981806c74e330b2d6f91db5_hd.jpg)  \n",
    "[图片地址](https://pic1.zhimg.com/v2-83f2f4b00981806c74e330b2d6f91db5_r.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "设随机变量Y={嫁，不嫁}  \n",
    "我们可以统计出，嫁的个数为6/12 = 1/2  \n",
    "不嫁的个数为6/12 = 1/2  \n",
    "那么Y的熵，根据熵的公式来算，可以得到H（Y） = -1/2log1/2 -1/2log1/2  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了引出条件熵，我们现在还有一个变量X，代表长相是帅还是帅  \n",
    "当已知不帅的条件下，满足条件的只有4个数据了，这四个数据中，不嫁的个数为1个，占1/4  \n",
    "嫁的个数为3个，占3/4  \n",
    "那么此时的H（Y|X = 不帅） = -1/4log1/4-3/4log3/4  \n",
    "p(X = 不帅) = 4/12 = 1/3  \n",
    "同理我们可以得到：  \n",
    "当已知帅的条件下，满足条件的有8个数据了，这八个数据中，不嫁的个数为5个，占5/8  \n",
    "嫁的个数为3个，占3/8  \n",
    "那么此时的H（Y|X = 帅） = -5/8log5/8-3/8log3/8  \n",
    "p(X = 帅) = 8/12 = 2/3  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有了上面的铺垫之后，我们终于可以计算我们的条件熵了，我们现在需要求：  \n",
    "H（Y|X = 长相）  \n",
    "也就是说，我们想要求出当已知长相的条件下的条件熵。  \n",
    "根据公式我们可以知道，长相可以取帅与不帅俩种  \n",
    "条件熵是另一个变量Y熵对X（条件）的期望。  \n",
    "公式为：  \n",
    "H（Y|X=长相） = p(X =帅)*H（Y|X=帅）+p(X =不帅)*H（Y|X=不帅）  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__ 我们用另一个变量对原变量分类后，原变量的不确定性就会减小了，因为新增了Y的信息，可以感受一下。不确定程度减少了多少就是信息的增益。__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://zhuanlan.zhihu.com/p/26486223  \n",
    "    https://www.zhihu.com/question/22104055 第二个回答"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 朴素贝叶斯\n",
    "- 先验与后验概率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "之所以称为朴素贝叶斯：因为有两个前提：\n",
    "- 假设所有时间都是独立分布的\n",
    "- 将设各个事件的重要性都是一样的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__  近代西方传统中，认为先验指无需经验或先于经验获得的知识。它通常与后验知识相比较，后验意指“在经验之后”，需要经验。这一区分来自于中世纪逻辑所区分的两种论证，从原因到结果的论证称为“先验的”，而从结果到原因的论证称为“后验的”__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 一般来说 先验证概率是 我们通过概率公式计算出来的，后验概率根据实际情况对先验概率进行验证，一样是贝叶斯公式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[先验概率与后验概率讲解](https://www.cnblogs.com/yemanxiaozu/p/7680761.html)  \n",
    "[朴素贝叶斯讲解（可结合决策树算法）](http://blog.csdn.net/amds123/article/details/70173402)  \n",
    "[补充（可替换）](http://blog.csdn.net/li8zi8fa/article/details/76176597)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[图片](https://images2017.cnblogs.com/blog/1234526/201710/1234526-20171017121446662-526159147.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考 第一个链接：贝叶斯公式的分母是分嫁与不嫁这个两个条件下的总和，是使用全概率求和的公式计算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 目前来看 这些算法不涉及到 最优化求解问题，直接计算相关出结果，根据结果的大小比较决定类别关系"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面介绍逻辑回归算法，涉及到最优化问题求解"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
